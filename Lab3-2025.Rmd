---
title: 'P&S-2025: Lab assignment 3'
author: "Bohdan Zasymovych, Arsenii Stratiuk, Yustyna Hayevska"
output:
  html_document:
    df_print: paged
---

### Work breakdown:

-   Bohdan Zasymovych: Task 1

-   Yustyna Hayevska: Task 2

-   Arsenii Stratiuk: Task 3

```{r}
options(width = 500)
id <- 10
```

# Task 1

### **Note**:

**In all derivations quantiles are defined to have next property** $P(X < q_{\alpha}) = \alpha$

$$
\lambda = \frac{1}{\theta}
$$

## 1)

$$X_i \sim \mathcal{E}(\lambda)$$

### Statistic:

$$T(\textbf{X}) = 2 \lambda n \overline{\textbf{X}}$$

$$n \overline{\textbf{X}} = n \frac{\sum X_i}{n} = \sum X_i \sim \Gamma(n, \lambda)$$

$$W(\textbf{X}) = n \overline{\textbf{X}} \sim \Gamma(n, \lambda) $$

MGF for Gamma distribution ($\Gamma(n, \lambda)$):

$$M(t) = (\frac{\lambda}{\lambda-t})^n$$

MGF for Chi-squared distribution with $n$ degrees of freedom ($\chi^2_n$):

$$M(t) = (1-2t)^{-\frac{n}{2}}$$

MGF of $T$:

$$M_{2 \lambda W}(2 \lambda t) = (\frac{\lambda}{\lambda-2 \lambda t})^n = (1-2 t)^{-n}$$

So $T$ has Chi-squared distribution with $2n$ degrees of freedom ($T \sim \chi^2_{2n}$)

### Probability:

$$
\begin{align}
1 - \alpha &= P\left(x_{\alpha/2} \le T \le x_{1-\alpha/2}\right) =
P\left(x_{\alpha/2} \le 2 \lambda W \le x_{1-\alpha/2}\right) \newline
&= P\left(x_{\alpha/2} \le \frac{2W}{\theta} \le x_{1-\alpha/2}\right)
= P\left(\frac{1}{x_{1-\alpha/2}} \le \frac{\theta}{2W} \le \frac{1}{x_{\alpha/2}}\right) \newline
&= P\left(\frac{2W}{x_{1-\alpha/2}} \le \theta \le \frac{2W}{x_{\alpha/2}}\right)
= P\left(\frac{2n \overline{\textbf{X}}}{x_{1-\alpha/2}} \le \theta \le \frac{2n \overline{\textbf{X}}}{x_{\alpha/2}}\right)
\end{align}
$$

### Confidence interval of confidence level $1 - \alpha$:

$$ \left[ \frac{2n \overline{\textbf{X}}}{x_{1-\alpha/2}}, \quad \frac{2n \overline{\textbf{X}}}{x_{\alpha/2}} \right]
$$

Here:

$x_{\alpha}$ - $\alpha$ quantile of $\chi^2_{2n}$

## 2)

$$
\overline{\textbf{X}} \sim \mathcal{N}(\frac{1}{\lambda}, \frac{1}{n\lambda^2}) \implies \overline{\textbf{X}} \sim \mathcal{N}(\theta, \frac{\theta^2}{n}) 
$$

$$
P \left( \frac{\sqrt{n} |\overline{\textbf{X}} - \theta|}{\theta} \le z_\alpha \right) = 2 \alpha - 1
$$

$$ \begin{align}
2 \alpha - 1 &= P \left( \frac{\sqrt{n} |\theta - \overline{\textbf{X}}|}{\theta} \le z_\alpha \right) = P \left( |\theta - \overline{\textbf{X}}| \le  \frac{\theta}{\sqrt{n}} z_\alpha \right) \newline
&= P \left( \overline{\textbf{X}} - \frac{\theta}{\sqrt{n}} z_\alpha \le  \theta \le  \overline{\textbf{X}} +\frac{\theta}{\sqrt{n}} z_\alpha \right)
\end{align}
$$

Confidence interval of confidence level $2 \alpha - 1$:

$$
\left[ \overline{\textbf{X}} - \frac{\theta}{\sqrt{n}} z_\alpha, \; \overline{\textbf{X}} + \frac{\theta}{\sqrt{n}} z_\alpha \right]
$$

But bounds of this interval for $\theta$ is dependent of $\theta$ itself so it cannot be used in practice.

## 3)

$$
2 \alpha - 1 = P \left( \frac{\sqrt{n} |\theta - \overline{\textbf{X}}|}{\theta} \le z_\alpha \right) = P \left( |\theta - \overline{\textbf{X}}| \le  \frac{\theta}{\sqrt{n}} z_\alpha \right)
$$

To find interval for $\theta$ with bounds independent of a parameter we need to solve next inequality:

$$
|\theta - \overline{\textbf{X}}| \le  \frac{\theta}{\sqrt{n}} z_\alpha
$$

Upper bound for $\theta$:

$$
\theta - \frac{\theta}{\sqrt{n}} z_\alpha \le \overline{\textbf{X}} \\
\theta \left(1 - \frac{z_\alpha}{\sqrt{n}}\right) \le \overline{\textbf{X}} \\
\theta \le \frac{\overline{\textbf{X}}}{1 - z_\alpha/\sqrt{n}}
$$

Lower bound for $\theta$:

$$
\theta + \frac{\theta}{\sqrt{n}} z_\alpha \ge \overline{\textbf{X}} \\
\theta \left(1 + \frac{z_\alpha}{\sqrt{n}}\right) \ge \overline{\textbf{X}} \\
\theta \ge \frac{\overline{\textbf{X}}}{1 + z_\alpha/\sqrt{n}}
$$

Final inequality and probability:

$$\frac{\overline{\textbf{X}}}{1 + z_\alpha/\sqrt{n}} \le \theta \le \frac{\overline{\textbf{X}}}{1 - z_\alpha/\sqrt{n}}$$

$$
P \left( \frac{\overline{\textbf{X}}}{1 + z_\alpha/\sqrt{n}} \le \theta \le \frac{\overline{\textbf{X}}}{1 - z_\alpha/\sqrt{n}} \right) = 2 \alpha - 1
$$

Confidence interval of confidence level $2 \alpha - 1$: $$
\left[ \frac{\overline{\textbf{X}}}{1 + z_\alpha/\sqrt{n}}, \quad \frac{\overline{\textbf{X}}}{1 - z_\alpha/\sqrt{n}} \right]
$$

## 4)

$$
Sxx := \sum (X_i - \overline{\textbf{X}})^2
$$

Estimator for the variance of the sample mean $\overline{\textbf{X}}$:

$$
\frac{Sxx}{n(n-1)}
$$

Statistic:

$$
T(\textbf{X}) = \frac{\overline{\textbf{X}} - \theta}{\sqrt{\frac{Sxx}{n(n-1)}}} \sim \mathcal{T}_{n-1}
$$

Probability:

$$
\begin{align}
1 - \alpha &= P \left( t_{\alpha/2} \le \frac{\overline{\textbf{X}} - \theta}{\sqrt{\frac{Sxx}{n(n-1)}}} \le t_{1-\alpha / 2}\right) \newline
&= P \left( \sqrt{\frac{Sxx}{n(n-1)}} t_{\alpha/2} \le \overline{\textbf{X}} - \theta \le \sqrt{\frac{Sxx}{n(n-1)}} t_{1-\alpha / 2}\right) \newline
&= P \left( - \overline{\textbf{X}} + \sqrt{\frac{Sxx}{n(n-1)}} t_{\alpha/2} \le - \theta \le - \overline{\textbf{X}} + \sqrt{\frac{Sxx}{n(n-1)}} t_{1-\alpha / 2}\right) \newline
&= P \left( \overline{\textbf{X}} + \sqrt{\frac{Sxx}{n(n-1)}} t_{\alpha/2} \le \theta \le \overline{\textbf{X}} - \sqrt{\frac{Sxx}{n(n-1)}} t_{\alpha / 2}\right)
\end{align}
$$

Confidence interval for $\theta$ of level $1-\alpha$:

$$
\left[ \overline{\textbf{X}} + \sqrt{\frac{Sxx}{n(n-1)}} t_{\alpha/2}, \; \overline{\textbf{X}} - \sqrt{\frac{Sxx}{n(n-1)}} t_{\alpha / 2} \right]
$$

Here:

$t_\alpha$ - $\alpha$ quantile of t-Student distribution with $n-1$ degrees of freedom ($\mathcal{T_{n-1}}$)

## Simulations:

```{r}
run_simulation_trial <- function(n, confidence, theta, lambda, m_reps, ci_checker_func) {
  results_matrix <- matrix(0, nrow = m_reps, ncol = 2)
  
  for (i in 1:m_reps) {
    x <- rexp(n, rate = lambda)
    
    results_matrix[i, ] <- ci_checker_func(x, theta, confidence)
  }
  
  avg_length <- mean(results_matrix[, 1])
  est_coverage_prob <- mean(results_matrix[, 2])
  
  return(list(
    avg_length = round(avg_length, 4),
    est_coverage_prob = round(est_coverage_prob, 4)
  ))
}


run_all_simulations_by_m <- function(theta, n_values, m_values, confidences, ci_checker_func) {
  lambda <- 1 / theta
  
  all_m_results <- list()
  
  for (m_reps in m_values) {
    
    prob_table <- matrix(NA, nrow = length(n_values), ncol = length(confidences),
                         dimnames = list(paste0("n=", n_values), paste0("confidence=", confidences, "__")))
    length_table <- matrix(NA, nrow = length(n_values), ncol = length(confidences),
                           dimnames = list(paste0("n=", n_values), paste0("confidence=", confidences, "__")))
    
    for (i in 1:length(n_values)) {
      n <- n_values[i]
      
      for (j in 1:length(confidences)) {
        confidence <- confidences[j]
        
        trial_results <- run_simulation_trial(n, confidence, theta, lambda, m_reps, ci_checker_func)
      
        prob_table[i, j] <- trial_results$est_coverage_prob
        length_table[i, j] <- trial_results$avg_length
      }
    }
    
    all_m_results[[paste0("m=", m_reps)]] <- list(
      coverage_table = prob_table,
      length_table = length_table
    )
  }
  
  return(all_m_results)
}
```

```{r}
ci_check_chi2 <- function(sample_x, theta, confidence) {
  
  alpha = 1 - confidence
  x_bar <- mean(sample_x)
  n <- length(sample_x)
  
  q_low <- alpha / 2
  q_high <- 1 - alpha / 2
  
  chi_low_quant <- qchisq(q_low, df = 2 * n)
  chi_high_quant <- qchisq(q_high, df = 2 * n)
  
  ci_low <- 2 * n * x_bar / chi_high_quant
  ci_high <- 2 * n * x_bar / chi_low_quant
  
  contains_theta <- (ci_low <= theta) && (theta <= ci_high)
  ci_length <- ci_high - ci_low
  
  return(c(ci_length, as.numeric(contains_theta)))
}


ci_check_snormal_dependent <- function(sample_x, theta, confidence) {
  
  alpha = (confidence + 1)/2
  x_bar <- mean(sample_x)
  n <- length(sample_x)
  
  z_a_quant <- qnorm(alpha, mean=0, sd=1)
  
  ci_low <- x_bar - (theta/sqrt(n)) * z_a_quant
  ci_high <- x_bar + (theta/sqrt(n)) * z_a_quant
  
  contains_theta <- (ci_low <= theta) && (theta <= ci_high)
  ci_length <- ci_high - ci_low
  
  return(c(ci_length, as.numeric(contains_theta)))
}


ci_check_snormal <- function(sample_x, theta, confidence) {
  
  alpha = (confidence + 1)/2
  x_bar <- mean(sample_x)
  n <- length(sample_x)
  
  z_a_quant <- qnorm(alpha, mean=0, sd=1)
  
  ci_low <- x_bar / (1 + z_a_quant / sqrt(n))
  ci_high <- x_bar / (1 - z_a_quant / sqrt(n))
  
  contains_theta <- (ci_low <= theta) && (theta <= ci_high)
  ci_length <- ci_high - ci_low
  
  return(c(ci_length, as.numeric(contains_theta)))
}


ci_check_tstudent <- function(sample_x, theta, confidence) {
  
  alpha = 1 - confidence
  x_bar <- mean(sample_x)
  sample_sd <- sd(sample_x)
  n <- length(sample_x)
  
  tstud_quant <- qt(alpha/2, df = n-1)
  
  ci_low <- x_bar + (sample_sd / sqrt(n)) * tstud_quant
  ci_high <- x_bar - (sample_sd / sqrt(n)) * tstud_quant
  
  contains_theta <- (ci_low <= theta) && (theta <= ci_high)
  ci_length <- ci_high - ci_low
  
  return(c(ci_length, as.numeric(contains_theta)))
}
```

```{r}
theta <- id/10 # =1
n_values <- c(10, 100, 1000, 10000)
m_values <- c(10, 100, 1000)
confidences <- c(0.90, 0.95, 0.99)
```

```{r}
simulation_results_chi2 <- run_all_simulations_by_m(theta, n_values, m_values, confidences, ci_check_chi2)
simulation_results_snormal_dependent <- run_all_simulations_by_m(theta, n_values, m_values, confidences, ci_check_snormal_dependent)
simulation_results_snormal <- run_all_simulations_by_m(theta, n_values, m_values, confidences, ci_check_snormal)
simulation_results_tstudent <- run_all_simulations_by_m(theta, n_values, m_values, confidences, ci_check_tstudent)
```

### Estimated confidences of the intervals

#### CI using Chi-squared distributed statistic

```{r}
for (m_label in names(simulation_results_chi2)) {
  res <- simulation_results_chi2[[m_label]]
  
  print(as.data.frame(res$coverage_table))
}
```

#### CI using standart normal distributed statistic with bounds dependent on $\theta$

```{r}
for (m_label in names(simulation_results_snormal_dependent)) {
  res <- simulation_results_snormal_dependent[[m_label]]
  
  print(as.data.frame(res$coverage_table))
}
```

#### CI using standart normal distributed statistic

```{r}
for (m_label in names(simulation_results_snormal)) {
  res <- simulation_results_snormal[[m_label]]
  
  print(as.data.frame(res$coverage_table))
}
```

#### CI using t-student distributed statistic

```{r}
for (m_label in names(simulation_results_tstudent)) {
  res <- simulation_results_tstudent[[m_label]]
  
  print(as.data.frame(res$coverage_table))
}
```

### Lengths of the intervals

#### CI using Chi-squared distributed statistic

```{r}
for (m_label in names(simulation_results_chi2)) {
  res <- simulation_results_chi2[[m_label]]
  
  print(as.data.frame(res$length_table))
}
```

#### CI using standart normal distributed statistic with bounds dependent on $\theta$

```{r}
for (m_label in names(simulation_results_snormal_dependent)) {
  res <- simulation_results_snormal_dependent[[m_label]]
  
  print(as.data.frame(res$length_table))
}
```

#### CI using standart normal distributed statistic

```{r}
for (m_label in names(simulation_results_snormal)) {
  res <- simulation_results_snormal[[m_label]]
  
  print(as.data.frame(res$length_table))
}
```

#### CI using t-student distributed statistic

```{r}
for (m_label in names(simulation_results_tstudent)) {
  res <- simulation_results_tstudent[[m_label]]
  
  print(as.data.frame(res$length_table))
}
```

In the tests each dataframe correspond to different number of repetitions of the test ($m: 10,\, 100,\, 1000$)

For each number of repetitions 12 tests were conducted varying number of samples ($n: 10,\, 100,\, 100,\, 10000$) and confidence levels of intervals (confidence: $0.9,\, 0.95,\, 0.99$).

## Results

In this task, four methods of creating confidence intervals (CIs) for estimating the mean of exponentially distributed random variables were tested. Their empirical confidence levels and interval lengths were also examined. Tests were conducted with different numbers of repetitions ($m$), sample sizes ($n$), and confidence levels.

The first observation is that when $m$ increases, the estimated confidence levels become closer to the theoretical values due to the LLN. The same effect appears when $n$ increases.

For all methods, when $n$ and $m$ are large, the empirical confidence levels are close to the expected theoretical values, indicating that the CIs were derived correctly.

The interval which has bounds dependent on the parameter $\theta$ has the smallest length of all constructed intervals for all values of $n$ and all confidence levels. Also, it can be easily shown that the length of this interval does not depend on the observed data and is constant for a fixed $n$ and confidence level:

$$
\text{LENGTH} = \overline{\textbf{X}} + \frac{\theta}{\sqrt{n}} z_\alpha - \left( \overline{\textbf{X}} - \frac{\theta}{\sqrt{n}} z_\alpha \right) = \frac{2\theta}{\sqrt{n}} z_\alpha
$$

Tests are consistent with this fact: for all tested numbers of repetitions ($m$), all lengths are exactly the same. Since this interval does not depend on the observed data and uses both the known variance and known parameter $\theta$, it has the smallest possible length due to eliminated uncertainty. However, it is impractical. We used the parameter $\theta$ to create this interval which estimates $\theta$ itself. In practice, there is no sense in estimating a parameter if the exact value is known. That is why this method won't be included in the further analysis.

As $n$ increases, interval lengths decrease. This happens because the bounds of all three intervals include division by $n$, so increasing $n$ makes them converge toward the true parameter. In simple terms, larger samples give better parameter estimates. Intervals with higher confidence levels are longer because greater precision requires greater length.

For very small samples ($n=10$), CIs based on the t-student statistic produce the shortest intervals for all confidence levels. CIs based on the chi-squared statistic are slightly longer. The method using the statistic approximated by the standard normal distribution (via the CLT) produces much longer intervals, and the difference grows with higher confidence levels.

Although the estimated confidence levels are close to expectations, small deviations appear. For the CI using the chi-squared statistic, results almost match the theoretical value, since the statistic is distributed exactly as $\chi^2_{2n}$ without any approximation. For the other two methods, the normal approximation of the sample mean is imperfect. The high skewness of the exponential distribution leads to undercoverage, especially for small sample sizes.

In conclusion, if the distribution is not exactly exponential, only the methods using the standard normal or t-student statistics can be applied. If the variance is unknown, only the method using the t-student statistic is valid. For small sample sizes, if the variance is known and the distribution is exactly exponential, the best method is the chi-squared–based CI because it gives relatively short intervals without undercoverage. For small samples where the variance is unknown or the variables are not exactly exponentially distributed, the CI using the t-student statistic should be preferred. For large enough sample sizes ($>30$), all methods yield nearly the same results (given whether the variance is known and whether the distribution is exponential).

# Task 2

Problem 2 (1 pt). Repeat parts (2)–(4) of Problem 1 (with corresponding amendments) for a Poisson distribution P($\theta$). Task and Directions remain the same; in other words, you have to check that confidence intervals constructed there contain the parameter $\theta$ with prescribed probability.

Directions:\
- use $\theta$ = id num/10 and α = 0.1; 0.05; 0.01; - vary the sample sizes n and the number m of repetitions to estimate the probability and comment on the results.

```{r}
id <- 10
set.seed(id)

theta <- id/10 # = 1/lambda
n_vals <- c(10, 100, 1000, 10000) #sample sizes
m <- 10000 #repetitions
alpha_vals <- c(0.1, 0.05, 0.01)
```

## (a) Confidence intervals

verify that the confidence intervals of level 1 − α constructed via 2.–4. above contain the parameter θ = 1/λ approx. 100(1 − α)% of times

### (2)

$X_1, X_2, \ldots, X_n$ have a Poisson distribution $\text{Pois}(\theta)$.\
For a Poisson random variable, $$
E[X_i] = \theta, \quad \operatorname{Var}(X_i) = \theta.
$$ Confidence interval for theta can be formed using the normal approximation for $\bar{X}$$$
\bar{X} \sim N\!\left(\mu = \theta, \, \sigma^2 = \frac{\theta}{n}\right).
$$

We standardize the sample mean: $$
Z = \frac{\bar{X} - \theta}{\sqrt{\theta / n}} 
     = \frac{\sqrt{n}(\bar{X} - \theta)}{\sqrt{\theta}}
     \sim N(0,1).
$$

$$
P(|Z| \le z_{1 - \alpha/2}) = 1 - \alpha.
$$ $$
P\!\left(
\left| \frac{\sqrt{n}(\bar{X} - \theta)}{\sqrt{\theta}} \right|
\le z_{1 - \alpha/2}
\right) = 1 - \alpha.
$$

$$
P\!\left(
|\bar{X} - \theta| \le 
z_{1 - \alpha/2} \frac{\sqrt{\theta}}{\sqrt{n}}
\right) = 1 - \alpha.
$$

Confidence interval of confidence level $1-\alpha$:

$$
{
\theta \in 
\left[
\bar{X} - z_{1-\alpha/2}\frac{\sqrt{\theta}}{\sqrt{n}},
\;
\bar{X} + z_{1-\alpha/2}\frac{\sqrt{\theta}}{\sqrt{n}}
\right].
}
$$

### (3)

This interval assumes that the population variance = $\theta$ is known. In practice, $\theta$ is unknown, so we solve the double inequality$$
|\bar{X} - \theta| \le z_{1-\alpha/2}\frac{\sqrt{\theta}}{\sqrt{n}},
$$ $$
(\bar{X} - \theta)^2 \le z_{1-\alpha/2}^2 \frac{\theta}{n}.
$$

$$
\bar{X}^2 - 2\bar{X}\theta + \theta^2 
   \le z_{1-\alpha/2}^2 \frac{\theta}{n}.
$$

$$
\theta^2 
   - \theta\!\left( 2\bar{X} + \frac{z_{1-\alpha/2}^2}{n} \right) 
   + \bar{X}^2 \le 0.
$$

Replacement $b = 2\bar{X} + \frac{z_{1-\alpha/2}^2}{n}$ , $c = \bar{X}^2$ $$
\theta^2 - b\theta + c \le 0,
$$

$$
\theta_{1,2} = 
\frac{b \pm \sqrt{b^2 - 4c}}{2}.
$$

$$
\theta_{1,2} = 
\frac{1}{2}
\left[
  \left( 2\bar{X} + \frac{z_{1-\alpha/2}^2}{n} \right)
  \pm
  \sqrt{
    \left( 2\bar{X} + \frac{z_{1-\alpha/2}^2}{n} \right)^2
    - 4\bar{X}^2
  }
\right].
$$

$$
\left( 2\bar{X} + \frac{z_{1-\alpha/2}^2}{n} \right)^2 - 4\bar{X}^2
= \frac{4z_{1-\alpha/2}^2\bar{X}}{n} + \frac{z_{1-\alpha/2}^4}{n^2}.
$$

Confidence interval of confidence level $1-\alpha$:

$$
{
\theta \in 
\left[
\frac{1}{2}
\left(
  2\bar{X} + \frac{z_{1-\alpha/2}^2}{n}
  \pm
  z_{1-\alpha/2}
  \sqrt{\frac{4\bar{X}}{n} + \frac{z_{1-\alpha/2}^2}{n^2}}\right)
\right]
}
$$

### (4)

The interval in (2) relied on the $\theta$. To construct a practical confidence interval that does not depend on the unknown $\theta$, we can replace the population variance by its sample estimate.$$
s^2 = \widehat{\sigma^2} = \widehat{\theta} = \bar{X},
$$ $$
s = \sqrt{\bar{X}}.
$$

Approximate the distribution using Student distribution: $$
T = \frac{\sqrt{n}(\bar{X} - \theta)}{s} \approx t_{n-1}
$$ $$
P\!\left(
|T| \le t_{1-\alpha/2,\,n-1}
\right) = 1 - \alpha
$$ $$
P\!\left(
\left| \frac{\sqrt{n}(\bar{X} - \theta)}{s} \right|
  \le t_{1-\alpha/2,\,n-1}
\right) = 1 - \alpha
$$

$$
P\!\left(
|\bar{X} - \theta|
  \le t_{1-\alpha/2,\,n-1} \frac{s}{\sqrt{n}}
\right) = 1 - \alpha
$$

$$
s = \sqrt{\bar{X}}.
$$

Confidence interval of confidence level $1-\alpha$: $$
{
\theta \in 
\left[
  \bar{X}
  - t_{1-\alpha/2,\,n-1}\frac{\sqrt{\bar{X}}}{\sqrt{n}},
\;
  \bar{X}
  + t_{1-\alpha/2,\,n-1}\frac{\sqrt{\bar{X}}}{\sqrt{n}}
\right]
}
$$

```{r}
problem2 <- function(alpha2, n2, m2, theta2){
  z <- qnorm(1 - alpha2/2, mean = 0, sd = 1) # z-quantile N(0, 1)
  t <- qt(1 - alpha2/2, df = n2-1) # t-quantile for Student dist. with param 1 - alpha/2
  
  cover2 <- cover3 <- cover4 <- 0 #coverage
  len2 <- len3 <- len4 <- 0 #length
  
    for (i in 1:m2){
      x <- rpois(n2, theta2) # random sample from Poi(theta), size n
      x_bar <- mean(x)

      #bounds using standart normal dist. with known variance
      up2 <- x_bar + z * sqrt(theta2/n2)
      low2 <- x_bar - z * sqrt(theta2/n2)
      if (low2 <= theta2 && theta2 <= up2){
        cover2 <- cover2 + 1
      }
      len2 <- len2 + (up2-low2) # next devide by m, so we'll have mean of len
      
      #bounds using standart normal dist. with unknown variance
      up3 <- (1/2) * ((2*x_bar) + ((z^2)/n2) + z * sqrt((4*x_bar/n2) + ((z^2)/(n2^2))) )
      low3 <- (1/2) * ((2*x_bar) + ((z^2)/n2) - z * sqrt((4*x_bar/n2) + ((z^2)/(n2^2))) )
      if (low3 <= theta2 && theta2 <= up3){
        cover3 <- cover3 + 1
      }
      len3 <- len3 + (up3-low3)
      
      #bounds using student dist. with unknown variance
      up4 <- x_bar + t * sqrt(x_bar/n2)
      low4 <- x_bar - t * sqrt(x_bar/n2)
      if (low4 <= theta2 && theta2 <= up4){
        cover4 <- cover4 + 1
      }
      len4 <- len4 + (up4-low4)
      
    }
  data.frame(
    alpha = alpha2,
    n = n2,
    cover2 = cover2/m2,
    cover3 = cover3/m2,
    cover4 = cover4/m2,
    len2 = len2/m2,
    len3 = len3/m2,
    len4 = len4/m2
  )
}

res <- data.frame()
for (alpha in alpha_vals){ # for confidence levels = (0.1, 0.05, 0.01)
   for (n in n_vals){ # different sample sizes = (10, 100, 1000, 10000)
    curr <- problem2(alpha, n, m, theta)
    res <- rbind(res, curr)
  }
}
print(res)
```

## (b) compare their precision (lengths)

The average lengths of the confidence intervals (len2, len3, len4) show the expected statistical behavior.

-   The **interval length decreases as the sample size n increases**.\
    This happens because the standard error of the sample mean is proportional to $\theta/\sqrt{n}$, $\theta = 1$ so $\bar X = 1/\sqrt{n}$.\
    Larger samples provide more information, so the estimation of $\theta$ becomes more precise.

-   The **interval length increases as the confidence level** (1 − $\alpha$) **increases**.\
    Smaller $\alpha$ (0.01 instead of 0.1) corresponds to a higher z- or t‑quantile, which makes the interval wider, so get higher coverage probability.

-   **(2)** (known $\theta$) gives the **shortest intervals**, because it assumes we know the true variance.\

-   **(3)** gives a bit **wider intervals**, since it includes estimation uncertainty.\

-   **(4)** is the **widest**, because the t‑distribution has bigger tails than the normal, especially for small sample sizes.

In summary,\
Interval length decreases with n, increases with confidence level, depends on true variance or variance estimation.

## (c) recommendation

give your recommendation as to which of the four methods is the best one and explain your decision

Based on the analysis results and accessibility in use, best method to form confidence intervals is **method (3)**.

1.  Method (3) achieves coverage probabilities that are closest to the nominal confidence levels (1 − $\alpha$), both for small and large samples. It does not underestimate or overestimate the true coverage significantly.
2.  It doesn't use $\theta$, which is usually unknown, by replacing it with estimated value - sample mean.
3.  It's average length of intervals is only slightly larger than Method (2), but clearly shorter than in Method (4).
4.  It provides the best precision for small sample sizes.

## Symmary of 2 Task

This task tests several ways of forming confidence intervals for the mean parameter $\theta$ of a Poisson distribution. Approximations used were: the normal interval with known variance, an interval that removes dependence on $\theta$, and a t‑based interval using the sample variance estimate. Their performance was done with $\theta = 1$, confidence levels $(1 - \alpha) = 0.9, 0.95, 0.99$, and sample sizes ranging from 10 to 10,000.

The simulations show that all three procedures produce empirical coverage close to the intended confidence level, especially as the sample size increases. For small samples, minor deviations occur due to the limited accuracy of the normal approximation, but they rapidly disappear with larger n. The behavior of interval lengths follows theoretical expectations: intervals become shorter as the sample size grows and they expand as the confidence level increases because of larger critical values.

In comparing the methods, the interval with z-quantile (standart normal distribution) based on known variance is the narrowest but not practically usable since the true parameter must be known. The second method's interval with z-quantile performs almost identically in coverage, while avoiding dependence on unknown quantities, and its average length is only slightly greater. The t‑based method produces the widest intervals, particularly for small n, reflecting the greater uncertainty accounted for by the heavier tails of the Student distribution.

Overall, the results align with theoretical predictions and confirm that increasing the sample size improves the precision of all interval estimates. Among the three tested methods, the second normal interval offers the most reasonable trade‑off between reliability and efficiency. It is easy to compute, does not require knowledge of the true variance, and maintains coverage probabilities near the nominal values, making it the preferred method for practical applications involving Poisson data.

# Task 3

### **Problem Formulation**

We aim to compare two estimators for the population variance $\sigma^2$: the standard sample variance $\sigma^2_{n-1}$ (dividing by $n-1$) and the intuitive variance $\sigma^2_n$ (dividing by $n$). We will determine which one is "unbiased" (meaning its expected value equals the true parameter) by simulating samples from a Normal distribution with known variance $\sigma^2=4$ and calculating the bias for different sample sizes $n$.

### **R Code**

```{r}
# set seed for reproducibility (team id 10)
set.seed(10)

# parameters
mu <- 10
sigma_sq <- 4
m <- 10000  # number of repetitions to estimate expected value
ns <- c(10, 50, 100, 1000) # sample sizes

# vectors to store bias results
bias_n <- numeric(length(ns))
bias_n_minus_1 <- numeric(length(ns))

# setup for plotting
par(mfrow=c(2,2)) 

for (i in 1:length(ns)) {
  n <- ns[i]
  
  # generate m samples of size n (matrix with n rows, m cols)
  samples <- matrix(rnorm(n * m, mean = mu, sd = sqrt(sigma_sq)), nrow = n)
  
  # calculate standard unbiased variance (dividing by n-1)
  vars_unbiased <- apply(samples, 2, var)
  
  # calculate biased variance (dividing by n)
  # recover sum of squares by multiplying by (n-1), then divide by n
  vars_biased <- vars_unbiased * (n - 1) / n
  
  # calculate bias: mean of estimates minus true sigma_sq
  bias_n_minus_1[i] <- mean(vars_unbiased) - sigma_sq
  bias_n[i] <- mean(vars_biased) - sigma_sq
  
  # determine range to fit both histograms
  x_min <- min(c(vars_unbiased, vars_biased))
  x_max <- max(c(vars_unbiased, vars_biased))
  
  # plot unbiased (blue, transparent)
  hist(vars_unbiased, breaks=30, prob=TRUE, 
       col=rgb(0, 0, 1, 0.4), border="white",
       xlim=c(x_min, x_max),
       main=paste("Variance Estimators (n =", n, ")"), 
       xlab="Variance Estimate")
  
  # plot biased (red, transparent)
  hist(vars_biased, breaks=30, prob=TRUE, 
       col=rgb(1, 0, 0, 0.4), border="white", add=TRUE)
  
  # add vertical line for true variance
  abline(v = sigma_sq, col="black", lwd=2, lty=2)
  
  # add legend
  if (i == 1) { # Only add legend to the first plot to save space
    legend("topright", legend=c("Unbiased (n-1)", "Biased (n)", "True Sigma^2"), 
           fill=c(rgb(0,0,1,0.4), rgb(1,0,0,0.4), NA), 
           lty=c(NA, NA, 2), lwd=c(NA, NA, 2), border="white", bty="n", cex=0.8)
  }
}

# reset plotting layout
par(mfrow=c(1,1))

# output results table
results <- data.frame(
  sample_size = ns,
  bias_biased_n = bias_n,
  bias_unbiased_n_1 = bias_n_minus_1
)

print(results)
```

**Visual Analysis:**

The histograms visually demonstrate the concept of estimator bias:

**At** $n=10$ (Top Left): There is a clear separation. The **Red distribution (Biased)** is shifted to the left of the true value (Dashed Line at 4). This confirms that dividing by $n$ systematically underestimates the variance. The **Blue distribution (Unbiased)** is centered correctly on the dashed line.

**At** $n=1000$ (Bottom Right): The distributions overlap almost perfectly. This confirms that as sample size increases, the difference between dividing by $n$ and $n-1$ becomes negligible, and the bias vanishes.

### **Justification (Theoretical Derivation)**

**Derivation of Expectations (Task e):**

Let $SS = \sum_{i=1}^{n}(X_i - \overline{X})^2$.

We know that $\sum_{i=1}^{n}(X_i - \overline{X})^2 = \sum_{i=1}^{n}(X_i - \mu)^2 - n(\overline{X} - \mu)^2$.

Taking the expectation:

$$E[SS] = \sum_{i=1}^{n}E[(X_i - \mu)^2] - nE[(\overline{X} - \mu)^2]$$

Since $E[(X_i - \mu)^2] = \sigma^2$ and $E[(\overline{X} - \mu)^2] = Var(\overline{X}) = \sigma^2/n$:

$$E[SS] = n\sigma^2 - n(\frac{\sigma^2}{n}) = n\sigma^2 - \sigma^2 = (n-1)\sigma^2$$

**Proof of Unbiasedness (Task f):**

**For** $\sigma^2_{n-1}$:

$$E[\sigma^2_{n-1}] = E\left[\frac{1}{n-1} SS\right] = \frac{1}{n-1} (n-1)\sigma^2 = \sigma^2$$

Since $E[\sigma^2_{n-1}] = \sigma^2$, this estimator is **unbiased**.

**For** $\sigma^2_{n}$:

$$E[\sigma^2_{n}] = E\left[\frac{1}{n} SS\right] = \frac{1}{n} (n-1)\sigma^2 = \frac{n-1}{n}\sigma^2$$

Since $E[\sigma^2_{n}] \neq \sigma^2$, this estimator is **biased**.

### **Conclusion**

**Reliability and Common Sense (Tasks d & g):**

**Bias Analysis:** The simulation results confirm the theory. The bias for $\sigma^2_{n-1}$ is extremely close to 0 for all $n$ (random fluctuation). The bias for $\sigma^2_n$ is negative (approx $-0.4$ for $n=10$), meaning it underestimates the population variance.

**Effect of** $n$: The theoretical bias of $\sigma^2_n$ is $\sigma^2(\frac{n-1}{n} - 1) = -\frac{\sigma^2}{n}$. As $n$ increases (for example, to $n=1000$), this term approaches 0.

**Agreement:** Practical results agree with common sense expectations; for small sample sizes, dividing by $n$ instead of $n-1$ significantly underestimates the spread of the data because the sample mean is used instead of the true population mean, which minimizes the sum of squares.
